# streamlit_app.py
import streamlit as st
import pandas as pd
import requests

# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ
st.set_page_config(layout="wide")
st.title("ARE YOU DAANGN?")

# --- ì„¸ì…˜ ìƒíƒœ í”Œë˜ê·¸ ---
if "is_searching" not in st.session_state:
    st.session_state.is_searching = False
if "stop_search" not in st.session_state:
    st.session_state.stop_search = False

# --- 1) ì§€ì—­ ì½”ë“œ CSV ë¡œë“œ ---
@st.cache_data
def load_regions():
    df = pd.read_csv("address_with_all_codes.csv", dtype=str)
    df["ê´‘ì—­"] = df["ê²€ìƒ‰ì–´"].map(lambda x: x.split()[0])
    MAJORS = [
        "ì„œìš¸íŠ¹ë³„ì‹œ","ë¶€ì‚°ê´‘ì—­ì‹œ","ëŒ€êµ¬ê´‘ì—­ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê´‘ì£¼ê´‘ì—­ì‹œ",
        "ëŒ€ì „ê´‘ì—­ì‹œ","ìš¸ì‚°ê´‘ì—­ì‹œ","ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ","ê²½ê¸°ë„","ê°•ì›íŠ¹ë³„ìì¹˜ë„",
        "ì¶©ì²­ë¶ë„","ì¶©ì²­ë‚¨ë„","ì „ë¼ë¶ë„","ì „ë¼ë‚¨ë„","ê²½ìƒë¶ë„","ê²½ìƒë‚¨ë„","ì œì£¼íŠ¹ë³„ìì¹˜ë„"
    ]
    return df, MAJORS

regions_df, MAJORS = load_regions()

# --- 2) ê²€ìƒ‰ ëª¨ë“œ & ì…ë ¥ ì˜ì—­ ---
mode_col, input_col, key_col = st.columns([1,4,3])
with mode_col:
    mode = st.radio("ğŸ” ëª¨ë“œ", ["ì „êµ­ ê²€ìƒ‰", "ì§€ì—­ ê²€ìƒ‰"], index=1, horizontal=True)
with input_col:
    item = st.text_input("ì°¾ì„ ë¬¼í’ˆ (ex: ë…¸íŠ¸ë¶)", "")
with key_col:
    kws = st.text_input(
        "í•µì‹¬ í‚¤ì›Œë“œ - ì‰¼í‘œë¡œ êµ¬ë¶„(ex: ê²Œì´ë°, 3060)",
        help="ex: ê²Œì´ë°, 3060  â†’ ì œëª©+ë‚´ìš©ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤"
    )
    keywords = [w.strip().lower() for w in kws.split(",") if w.strip()]

# --- 3) ì§€ì—­ ê²€ìƒ‰ í•„í„° ---
if mode == "ì§€ì—­ ê²€ìƒ‰":
    with st.expander("ì§€ì—­ í•„í„° ì„¤ì •", expanded=True):
        maj_sel = st.multiselect("ê´‘ì—­ ì„ íƒ", MAJORS, default=MAJORS[:3])
        sub_df = regions_df[regions_df["ê´‘ì—­"].isin(maj_sel)]
        sub_opts = sorted(sub_df["ê²€ìƒ‰ì–´"].unique())
        sub_sel = st.multiselect("ë™/ì/ë©´ ì„ íƒ (ë¹„ì›Œë‘ë©´ ëª¨ë‘)", sub_opts)
        if not sub_sel:
            sub_sel = sub_opts.copy()
else:
    maj_sel = []
    sub_sel = []

# --- 4) í˜ì´ì§€ë„¤ì´ì…˜ ---
pag1, pag2 = st.columns(2)
with pag1:
    per_page = st.number_input("í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜", 5, 50, 10, 5)
with pag2:
    page = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 100, 1, 1)

# --- 5) ë‚´ë¶€ API í˜¸ì¶œ í•¨ìˆ˜ ---
@st.cache_data
def fetch_articles(region_tag, query, page, limit):
    url = "https://www.daangn.com/kr/buy-sell/"
    params = {
        "in":     region_tag,
        "search": query,
        "_data":  "routes/kr.buy-sell._index",
        "page":   page,
        "limit":  limit
    }
    headers = {
        "Accept":     "application/json, text/plain, */*",
        "Referer":    "https://www.daangn.com/kr/buy-sell/",
        "User-Agent": "Mozilla/5.0"
    }
    r = requests.get(url, params=params, headers=headers)
    r.raise_for_status()
    return r.json()

# --- 6) ì‹œì‘/ì¤‘ì§€ ë²„íŠ¼ ---
col_start, col_stop = st.columns([1,1])
with col_start:
    if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘"):
        st.session_state.is_searching = True
        st.session_state.stop_search = False
with col_stop:
    if st.button("ğŸ›‘ ê²€ìƒ‰ ì¤‘ì§€"):
        st.session_state.stop_search = True

# --- 7) ê²€ìƒ‰ ì‹¤í–‰ & ì ì§„ì  ë Œë”ë§ ---
if st.session_state.is_searching:
    # ëŒ€ìƒ ì§€ì—­ ê²°ì •
    if mode == "ì „êµ­ ê²€ìƒ‰":
        regions_to_search = regions_df["ê²€ìƒ‰ì–´"].tolist()
    else:
        regions_to_search = sub_sel

    total = len(regions_to_search)
    progress = st.progress(0)
    result_container = st.empty()
    all_rows = []

    for idx, region in enumerate(regions_to_search):
        # ì¤‘ì§€ í”Œë˜ê·¸ ì²´í¬
        if st.session_state.stop_search:
            st.warning("ğŸ›‘ ê²€ìƒ‰ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break

        # region ì½”ë“œ, API í˜¸ì¶œ
        code = regions_df.loc[
            regions_df["ê²€ìƒ‰ì–´"] == region, "region_code"
        ].iat[0]
        tag = f"{region}-{code}"
        data = fetch_articles(tag, item, page, per_page)
        arts = data.get("allPage", {}).get("fleamarketArticles", [])

        for art in arts:
            text = (art["title"] + " " + art["content"]).lower()
            if keywords and not all(kw in text for kw in keywords):
                continue
            
            # ê°€ê²©ì„ ë¬¸ìì—´ â†’ ì •ìˆ˜ë¡œ ë³€í™˜
            raw_price = art["price"]
            try:
                price_int = int(float(raw_price))
            except:
                price_int = None
            all_rows.append({
                "ê´‘ì—­":      region.split()[0],
                "ì§€ì—­":      region,
                "ì œëª©":      art["title"],
                "ê°€ê²©":      price_int,
                "ë“±ë¡ì‹œê°„":  art["createdAt"],
                "íŒë§¤ì":    art["user"]["nickname"],
                "ì—…ë¡œë“œì§€ì—­": data["region"]["depth3RegionName"],
                "ë§í¬":      art["href"],
                "ì¸ë„¤ì¼":    art["thumbnail"],
                "ì„¤ëª…":      art["content"][:80] + "â€¦"
            })

        # ì¤‘ê°„ ê²°ê³¼ ë Œë”ë§
        df_p = pd.DataFrame(all_rows)
        if not df_p.empty:
            df_p["ë“±ë¡ì‹œê°„"] = pd.to_datetime(df_p["ë“±ë¡ì‹œê°„"])
        result_container.dataframe(df_p, use_container_width=True)

        progress.progress((idx + 1) / total)

    # ê²€ìƒ‰ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
    st.session_state.is_searching = False

    # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
    if not all_rows:
        st.info("ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df_final = pd.DataFrame(all_rows)
        df_final["ë“±ë¡ì‹œê°„"] = pd.to_datetime(df_final["ë“±ë¡ì‹œê°„"])
        st.success(f"âœ… ì´ {len(df_final)}ê±´ ê²€ìƒ‰ ì™„ë£Œ")

        # ì „êµ­: í‘œ / ì§€ì—­: ì¹´ë“œë·°
        if mode == "ì „êµ­ ê²€ìƒ‰":
            st.dataframe(df_final, use_container_width=True)
        else:
            st.markdown("### ì¹´ë“œ ë·°")
            cols = st.columns(3, gap="small")
            for i, row in df_final.iterrows():
                c = cols[i % 3]
                with c:
                    st.image(row["ì¸ë„¤ì¼"], use_container_width=True)
                    st.markdown(f"**{row['ì œëª©']}**")
                    st.markdown(f"- ğŸ’° {row['ê°€ê²©']}ì›")
                    st.markdown(f"- ğŸ“ {row['ì—…ë¡œë“œì§€ì—­']} / {row['ì§€ì—­']}")
                    st.markdown(f"- ğŸ•’ {row['ë“±ë¡ì‹œê°„'].strftime('%Y-%m-%d %H:%M')}")
                    st.markdown(f"- ğŸ‘¤ {row['íŒë§¤ì']}")
                    st.markdown(f"[ğŸ”— ìƒì„¸ë³´ê¸°]({row['ë§í¬']})")
                    st.markdown("---")

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = df_final.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv,
            file_name="daangn_search_results.csv",
            mime="text/csv"
        )
